_target_: models.diffusion.unet.ControlNet
# from ControlNet
image_size: 32 # unused
in_channels: 3
hint_channels: 3
model_channels: 96
channel_mult: [ 1, 2, 2, 2 ]
# from idiff
input_channels: 3
initial_channels: 96
channel_multipliers:
  - 1
  - 2
  - 2
  - 2
is_attention:
  - false
  - true
  - true
  - true
attention_heads: -1
attention_head_channels: 32
n_blocks_per_resolution: 2
condition_type: "CA"                                          # ['AddPlusGN', 'AdaGN', 'DiffAE', 'CA']
is_context_conditional: True                                  # context is only used if this is True
n_context_classes: 0                    # set to 0 if context is not a discrete class label
context_input_channels: 512                                   # size of the input context embedding
context_channels: 256                                         # size of the shared context embedding across blocks
learn_empty_context: False                                     # add learnable embedding to the model for empty contexts
context_dropout_probability: 0.25
